# Identification-of-street-signs

The object of the work is the identification of road signs
For the practical implementation of software modules, the Python language and the Google Colab integrated development environment were chosen. A specific neural network model was chosen. A dataset of ... images was also created to train the model. A software module has been developed and tested.
As a result of the work, an artificial neural network model was trained, tested on a dataset and implemented into a software module. The developed program in the future, with its development, can be implemented into various vehicle management systems and driver assistance systems.
2 Подготовка данных и модели к программной реализации
Прежде чем переходить к непосредственно кодовой реализации нашей задачи, необходимо провести предварительную обработку данных и углубленно проанализировать выбранную архитектуру YOLOv8.
2.1 Предварительная обработка собранных данных
Собранный набор данных включает в себя 15 различных классов изображений дорожных указателей. Всего в наборе данных представлено 4969 изображений. Часть из этих изображений была собрана мной, а часть из них была взята из уже готовых датасетов. Ниже перечислим классы дорожных указателей, из которых и состоит датасет:
	Зеленый свет светофора
	Красный свет светофора
	Знак «Стоп»
	Знак «Ограничение максимальной скорости 10 км/ч»
	Знак «Ограничение максимальной скорости 100 км/ч»
	Знак «Ограничение максимальной скорости 110 км/ч»
	Знак «Ограничение максимальной скорости 120 км/ч»
	Знак «Ограничение максимальной скорости 20 км/ч»
	Знак «Ограничение максимальной скорости 30 км/ч»
	Знак «Ограничение максимальной скорости 40 км/ч»
	Знак «Ограничение максимальной скорости 50 км/ч»
	Знак «Ограничение максимальной скорости 60 км/ч»
	Знак «Ограничение максимальной скорости 70 км/ч»
	Знак «Ограничение максимальной скорости 80 км/ч»
	Знак «Ограничение максимальной скорости 90 км/ч»
Далее необходимо разметить наши данные. Разметка данных нужна для помощи в выявлении логических закономерностей, структурированию данных. Чем лучше будет произведена разметка данных, тем лучше пройдет обучение НС. Данный метод называется обучением с учителем, так как мы уже задаем правильные ответы, тем самым представляем нашей модели некий ориентир, по которому она может выявлять признаки и тем самым «обучаться».
Для разметки данных мною был выбран сайт Roboflow [6], который является одним из ведущих сайтов по предоставлению наборов данных для задач компьютерного зрения.
Для начала были созданы 15 классов, которыми потом мы будем давать метки нашим изображениям. Процесс создания метки класса представлен на рисунке 5.
 
Рисунок 5 - Создания меток класса
После создания классов мы непосредственно переходим к разметке набора данных. Процесс разметки запечатлен на рисунке 6. С помощью боковой панели инструментов справа и присвоения класса в графе слева происходит формирование ограничительной области и выдача ей соответствующей метки класса.
 
Рисунок 6 - Разметка изображения
Также все изображения стоит привести к единому размеру. Оптимальным размером было выбрано разрешение 416x416.
После разметки всех изображений мы можем экспортировать наш датасет. Большой плюс используемого сайта Roboflow заключается в предоставлении различных форматов экспорта данных. В современном мире два наиболее используемых формата хранения данных: COCO [7] и YOLO [8]. Процесс экспортирования датасета представлен на рисунке 7.
 
Рисунок 7 - Экспорт датасета
После эскпортирования данных в виде ZIP-архива и последующей его распаковки на компьютер мы получаем древовидную структуру каталога с датасетом (см. рисунок 8).
 
Рисунок 8 - Структура датасета
С сайта нам идет три папки для трех типов данных: тренировочных, валидационных и тестовых. Train, valid и test папки соответственно. Помимо папок в ZIP-архиве лежит файл data.yaml. В этом файле указываются пути до тренировочного, валидационного и тестового наборов данных, а также количество меток и их классы. Его структура представлена на рисунке 9.
 
Рисунок 9 - Структура файла data.yaml
Подробнее рассмотрим папки в каталоге. Все они имеют одинаковую структуру, представленную на рисунке 10.
 
Рисунок 10 - Структура папок train, valid, test
В папке images лежат наши изображения. В папке labels лежат аннотации к нашим изображениям в виде файла в формате txt с таким же названием, как и у изображения в папке images, к которому он прилагается. Рассмотрим, что из себя этот файл представляет (см. рисунок 11):
 
Рисунок 11 - Файл аннотации
Данный формат хранения аннотации называется аннотацией к детекции (bbox). Когда мы размечали датасет, мы выделяли дорожный указатель с помощью прямоугольника (ограничивающей области). Значения в данном текстовом файле по порядку слева-направо имеют следующий смысл:
	Номер класса знака на соответствующем изображении
	Центр прямоугольника по оси x
	Центр прямоугольника по оси y
	Ширина прямоугольника
	Высота прямоугольника
2.2 Выбор модели YOLOv8
Выбранная модель нейронной сети YOLOv8 обладает разновидностями моделей. В каждой категории моделей YOLOv8 есть по пять моделей для обнаружения, сегментации и классификации. YOLOv8 Nano - самая быстрая и компактная, в то время как YOLOv8 Extra Large (YOLOv8x) - самая точная, но при этом самая медленная из них. В таблице 2.1 представлена сравнительная характеристика, взятая с официального сайта создателей YOLOv8 [9].
Таблица 2.1 - Параметры моделей YOLOv8 для обнаружения на COCO
Модель	Размер
(пикселей)	mAPval
50-95	Скорость
CPU ONNX
(мс)	Скорость
A100 TensorRT
(мс)	Кол-во параметров
(млн.)	FLOPs
(млрд.)
YOLOv8n (Nano)	640	37.3	80.4	0.99	3.2	8.7
Продолжение таблицы 2.1
YOLOv8s (Small)	640	44.9	128.4	1.20	11.2	28.6
YOLOv8m (Medium)	640	50.2	234.7	1.83	25.9	78.9
YOLOv8l (Large)	640	52.9	375.2	2.39	43.7	165.2
YOLOv8x (Xtra Large)	640	53.9	479.1	3.53	68.2	257.8
В силу ограниченности имеющихся вычислительных мощностей, а также вследствие того факта, что в данной работе число классов не сильно велико (как упоминалось ранее, 15), а более «тяжеловесные» модели имеют больше параметров, как можно наблюдать из таблицы, это может повлечь за собой переобучение. Этим моделям требуется огромные тренировочные наборы данных для корректного обучения, даже наш набор, казалось бы, из почти 5 тысяч изображений для них является слишком простой задачей. Поэтому, в связи со всем вышеперечисленным, мною было принято решение выбрать модель YOLOv8n. 
2.3 Выводы по разделу
В данном разделе мы решили задачу по предварительной подготовке набора данных, выполнили разметку изображений, а также выбрали необходимую модель выбранной ранее архитектуры YOLOv8 – YOLOv8n.










3 Программная реализация программы распознавания дорожных знаков
В данном разделе будет представлена программная реализация кода для распознавания дорожных указателей. В качестве языка программирования был выбран Python [10], так как библиотека Ultralytics [11], которая содержит используемую нами модель YOLOv8, представлена только для этого языка. Помимо этого, его основными преимуществами в сфере работы с нейронными сетями являются:
	обширная среда библиотек для машинного обучения и нейронных сетей, таких как TensorFlow, PyTorch и Keras
	простота и читаемость
	широкий спектр инструментов для работы с анализом данным и визуализации данных
	активное сообщество разработчиков и пользователей
В качестве среды разработки я выбрал сервис Google Colab. Это бесплатная платформа, предлагаемая Google, которая позволяет писать и запускать код на Python в браузере. Его основные преимущества в сфере ML и ИИ включают в себя:
	доступность (облачный хостинг, предустановка множества библиотек, доступ к вычислительным ресурсам, но ограниченный)
	простота совместной работы (хранилище на Google-диске, импорт и эскпорт файлов разработки, совместная работа в режиме реального времени, интеграция с Github’ом)
	гибкость в программировании (доступ к внешним данным, многообразие режимов выполнения, интеграция документации)
3.1 Реализация программы идентификации дорожных указателей
На данном этапе работы мы уже имеем собранный и размеченный датасет, а также определились с выбором модели, которую будем использовать. После всех необходимых операций импорта библиотек и проверки предварительно обученной модели мы запускаем обучение нашей модели на наш набор данных. Запуск данной команды производился на вычислительных ресурсах ПК с ОС Windows в консольной строке. Пример запуска можно увидеть ниже:
 yolo detect train data=/content/drive/MyDrive/Kaggle dataset (Traffic sign detection)/data.yaml model=yolov8n.pt epochs=100 imgsz=416 batch=12 project=Diplom name=yolov8n_416
Разберем его:
	yolo – вызов соответствующей библиотеки
	detect – выбор опции работы из предложенных вариантов (детекция – detect, сегментация – segment, классификация – classify, определение позы – pose, обнаружение объектов с ориентированными ограничивающими рамками – obb)
	train – режим выполнения задачи (тренировка – train, val – валидация, predict – прогнозирование, export – экспорт модели, track – отслеживание, benchmark – оценка эффективности)
	data – путь до файла data.yaml
	model – выбор модели (yolov8n, yolov8ns, yolov8m, yolov8l, yolov8x)
	epochs – количество эпох (сколько раз датасет прошел через нейронную сеть полноценно – в прямом и обратном направлении)
	imgsz – размер изображения
	batch – размер партии (датасет делят на маленькие партии – батчи, то есть количество картинок, на которых тренируется нейронная сеть одновременно)
	project – название проекта
	name – название эксперимента
Процесс тренировки представлен на рисунке 12.
 
Рисунок 12 - Процесс обучения нейронной сети
Общее время тренировки нейронной сети составило около 30-35 минут. 
3.2 Анализ полученных результатов
После обучения нейронной сети мы можем оценить ее эффективность, используя различные метрики для этого. Существует множество различных методов и метрик для оценки. Рассмотрим самые главные из них, по которым мы и будем оценивать работу нашей нейронной сети.
3.2.1 Метрики оценки эффективности работы нейронной сети
Так как зачастую на изображении мы можем встретить объекты различных классов, задача их обнаружения нередко превращается в задачу распознавания и определения нужного класса объекта. Благодаря этому, обнаружение объектов легко сводится к проверке гипотез H1 (о наличии объекта) и H0 (об отсутствии объекта).
Результат данной проверки может привести к ошибкам 1-го и 2-го рода. Ошибка 1-го рода или так называемая «ложноположительная» ошибка состоит в неверном отвержении нулевой гипотезы H0 и ложном принятии гипотезы H1. Ошибка 2-го рода («ложноотрицательная») состоит в ошибочном принятии нулевой гипотезы H0.
Для решения задачи обнаружения есть возможность использовать метод полного перебора всех областей изображения. При этом необходимо уменьшить вероятность ошибки одного рода при заданном пороговом значении вероятности ошибки другого рода. Критериями эффективности такого подхода, в первую очередь, выступают доля правильных обнаружений и производительность алгоритма обнаружения. Последняя характеризуется числом стандартных кадров, обрабатываемых в единицу времени, либо временем, затрачиваемым на обработку стандартного кадра. Это приводит к необходимости оптимизации алгоритмов обнаружения с учетом задачи, которую необходимо решить [1].
Но помимо критериев корректного обнаружения, алгоритмы могут оцениваться по корректности определения самой области изображения, содержащей объект, например, метрикой loU (Intersection over Union – пересечение по объединению). Пересечение по объединению — это оценочная метрика, используемая для измерения точности детектора объектов в конкретном наборе данных. Мы часто видим, как эта метрика оценки используется в задачах обнаружения объектов. Любой алгоритм, который предоставляет прогнозируемые ограничивающие рамки в качестве выходных данных, может быть оценен с использованием IoU.
Более формально, чтобы применить IoU для оценки (произвольного) детектора объектов, нам нужны:
	Истинные ограничивающие рамки (т.е. помеченные вручную ограничивающие рамки из тестового набора, которые указывают, где на изображении находится наш объект).
	Предсказанные ограничивающие рамки из нашей модели.
Пока у нас есть эти два набора ограничивающих рамок, мы можем применять IoU.
Значение IoU является отношением площади, полученной в результате пересечения области, предсказанный алгоритмом, и реальной области с объектом, к площади, полученной в результате объединения этих областей. На рисунке 13 наглядно демонстрируется геометрический смысл метрики, где видно, если области совпадают, то значение IoU = 1, иначе IoU=0. На рисунке зона «А» - предсказанная алгоритмом зона расположения объекта, а зона «Б» - фактическое местоположение искомого объекта.
 
Рисунок 13 - Метрика IoU
Чтобы оценить производительность алгоритма обнаружения и локализации объектов, нам необходимо оценить, является ли прогнозируемый класс фактическим классом и насколько близок прогнозируемый ограничивающий прямоугольник к основной истине. Для этого и существует метрика под названием «Средняя точность» (AP) и «Интерполированная средняя точность» (mAP), которая позволяет как раз-таки оценить производительность нашего алгоритма. Но для ее понимания стоит разобраться с некоторыми другими метриками.
Прогноз считается правильным, если метка класса прогнозируемой ограничивающей рамки и основной истинной ограничивающей рамки одинакова, а IoU между ними превышает пороговое значение.
На основе IoU, порога и меток классов истинной истины и прогнозируемых ограничивающих рамок мы вычисляем следующие три метрики результата:
Истинно положительный (TP): модель предсказала, что ограничивающая рамка существует в определенной позиции (положительный результат), и это было правильно (истина).
Ложно положительный (FP): модель предсказала, что ограничивающая рамка существует в определенном положении (положительное), но это было неверно (ложное). Данный результат и называется ошибкой 1-го рода, о которой было сказано ранее.
Ложно отрицательный (FN): модель не предсказывала ограничивающую рамку в определенной позиции (отрицательно), и это было неправильно (ложно), т.е. в этой позиции существовала основная истинная ограничивающая рамка. Это является ошибкой 2-го рода. Подробная визуализация находится на рисунке 14.
 
Рисунок 14 - Метрики TP, FP, FN
Истинно отрицательный результат (TF): модель не предсказала ограничивающую рамку (отрицательный результат), и это было правильно (верно). Это соответствует фону, области без ограничивающих рамок и не используется для расчета окончательных показателей.
На основе TP, FP и FN для каждого помеченного класса мы рассчитываем два параметра: точность (precision) и полноту (recall).
Точность сообщает нам, насколько точна наша модель, т. е. насколько алгоритм способен обнаруживать объект, соответствующие требованиям. Следовательно, это соотношение между истинно положительными и общим количеством предсказаний (что эквивалентно сумме истинно положительных и ложно положительных результатов), сделанных моделью (1). 
Полнота показывает нам, насколько хорошо модель «заполняет» классы из изображений, т. е. сколько из общего числа объектов класса модель смогла обнаружить. Следовательно, это соотношение между истинно положительными и общим количеством истинно положительных (эквивалентно сумме истинно положительных и ложно отрицательных), полученных с помощью модели (2).
█(precision= TP/(TP+FP)  #(1))
█(recall= TP/(TP+FN)  ,#(2) )

где TP - число правильных решений о наличии объекта; FP - число ошибок первого рода; FN - число ошибок второго рода.
Геометрический смысл понятий полноты и точности демонстрируется на рисунке 15, где TN – количество правильных решений об отсутствии объекта [1]. 

 
Рисунок 15 - Геометрический смысл precision и recall
Чтобы обратиться к средней точности (AP) нам необходимо понять, что В идеале мы хотим, чтобы и точность, и полнота были высокими, т. е. все, что обнаружено, является правильным, и модель может обнаружить все вхождения класса. Значение точности и полноты зависит от того, сколько истинных положительных результатов было обнаружено моделью. Назначение ограничивающей рамки TP, FP и FN зависит от следующих двух факторов:
	Прогнозируемая метка по сравнению с истинной меткой
	IoU между двумя зонами определения
Для задачи многоклассовой классификации модель выводит условную вероятность того, что ограничивающий прямоугольник принадлежит определенному классу. Чем больше вероятность класса, тем больше шансов, что ограничивающий прямоугольник будет содержать этот класс. Распределение вероятностей вместе с определяемым пользователем пороговым значением (от 0 до 1) используется для классификации ограничивающего прямоугольника.
Чем меньше этот порог достоверности вероятности, тем выше количество обнаружений, сделанных моделью, и тем ниже вероятность того, что метки основной истины были пропущены и, следовательно, выше полнота (recall) (как правило, но не всегда). С другой стороны, чем выше порог уверенности, тем более уверена модель в том, что она предсказывает, и, следовательно, выше точность (precision) (как правило, но не всегда). Мы хотим, чтобы и точность, и полнота были как можно выше, поэтому существует компромисс между точностью и полнотой, основанный на значении порога достоверности.
Кривая точности-полноты (PR) отображает зависимость точности от отзыва для различных пороговых значений достоверности.
С помощью кривой точности отзыва мы можем визуально увидеть, какой доверительный порог лучше всего подходит для нас (для нашего конкретного приложения). Чрезмерно упрощенный пример кривой PR можно увидеть на рисунке 16.
 
Рисунок 16 - PR-кривая
Выбор значения достоверности может быть трудным и субъективным. Средняя точность (AP) – это ключевой показатель производительности, который пытается устранить зависимость выбора одного порогового значения достоверности и определяется как область под кривой PR.
AP суммирует кривую PR до одного скалярного значения. Средняя точность высока, когда и точность, и полнота высоки, и низкая, когда любой из них низок в диапазоне значений порога достоверности. Диапазон значений AP составляет от 0 до 1.
Average Precision (AP)= ∫_(R=0)^1▒P(R)dR
Для определения площади под кривой PR обычно используются следующие два подхода:
	Аппроксимируем кривую PR прямоугольниками
Для каждой пары точность-полнота (j=0,…, n-1) площадь под кривой PR можно найти путем аппроксимации кривой с помощью прямоугольников (см. рисунок 17).
Ширину таких прямоугольников можно найти, взяв разницу двух последовательных значений полноты (r(k), r(k-1)), а высоту можно найти, взяв максимальное значение точности для выбранных значений полноты. т. е
w=r(k)-r(k-1),h=max⁡(p(k),p(k-1))
 
Рисунок 17 - 1-ый подход
	Интерполяция и среднее значение по 11 точкам
Рассчитываются значения точности для 11 значений отзыва от 0,0 до 1,0 с шагом 0,1.

Эти 11 точек изображены как оранжевые образцы на рисунке 18. AP можно рассчитать, взяв среднее значение этих 11 значений точности. 

 Рисунок 18 - 2ой подход
Значение AP можно рассчитать для каждого класса. mAP же рассчитывается путем взятия среднего значения AP по всем рассматриваемым классам.
mAP=  1/k ∑_i^k▒〖AP〗_i ,
где k – количество классов
Но в некоторых задачах эти две характеристики означают то же самое. Например, для оценки проблемы COCO (сокращение от «Common Objects in Context» – «реальные объекты в контексте») нет разницы между AP и mAP.
Использование двух характеристик - точности и полноты позволяет более полно оценить качество работы алгоритма обнаружения по сравнению с расчетом доли верных обнаружений (accuracy):
█(accuracy= (TP+TN)/(TP+TN+FP+FN)  #(3) )
Это особенно актуально для несбалансированных данных, где количество объектов в одном классе может значительно превышать количество объектов в другом классе. Использование формулы (3) не дает возможности адекватно оценить качество работы алгоритма [1].
Для интегральной характеристики точности и полноты используют F-меру. Данная метрика рассчитывается в соответствии с формулой (4): 
█(F_β=(1+β^2 )  (precision*recall)/(β^2*precision*recall),#(4) )
где β- весовой коэффициент, определяющий вклад precision в значение F-меры.
Чаще всего весовой коэффициент β принимается равным единице и тогда F-мера превращается в F1-score.
F1-Score ¬¬– это мера, сочетающая точность и отзывчивость. Обычно его называют гармоническим средним из двух. Гармоническое среднее –это еще один способ вычисления «среднего» значений, который обычно описывается как более подходящий для соотношений (таких как точность и отзыв), чем традиционное среднее арифметическое. Формула, используемая для оценки F1 в этом случае:
█(F_1-score=2* (precision*recall)/(precision+recall))
Стремительно развивается множество метрик, которые могут быть использованы для оценки качества алгоритмов обнаружения. Таким образом, выбор метрик для конкретной задачи обосновывается необходимостью и должен быть специально подобран в каждом отдельном случае.
3.2.2 Оценка эффективности работы нашей модели
Удобство данной библиотеки заключается в том, что она автоматически генерирует различные графики, сводки, матрицы и заносит их в папку с обучением. Достаточно нужные результаты вывести на экран.
Представленные на рисунке 19 несколько строчек таблицы показывают нам как менялись значения точности, полноты и средней точности на последних эпохах тренировки в аналитическом виде. 
 
Рисунок 19 - Метрики оценки эффективности
Для наглядности эти же метрики представлены на рисунках 20-22 в виде визуализации.
 
Рисунок 20 - Кривая точности

 
Рисунок 21- Кривая полноты
 
Рисунок 22 - PR-кривая
Из представленных данных можем видеть, что к концу обучения точность нашей модели составило 0.95, а полнота 0.88. Данные значения являются достаточно неплохими показателями. Средняя точность для случаев, когда пороговое значение для IoU варьировалось от 0.5 до 0.95, составила 0.82, а для случаев с пороговым значением IoU, равной 0.5, равна 0.94. Данные значения показывают неплохую эффективность тренировки нашей модели на сборном наборе данных. 
Метрика F1-score представлена на рисунке 23. 
 
Рисунок 23 - F1-кривая
На данном графике мы можем видеть график метрики F1-score, являющейся средним гармоническим значением точности и полноты, при различных пороговых значениях. Самый высокий пик этой кривой – лучшая производительность.  Стоит отметить, что пороговые значения достоверности не являются случайными; они обычно выбираются таким образом, чтобы сбалансировать точность и запоминаемость, и часто оцениваются на основе набора валидационных данных. В нашем случае, в среднем модель имеет точность 92% при пороговом значении 0.399 для всех классов.
3.2.3 Создание программного модуля
При создании интерфейса для PyQt5 был использован PyQt Designer, также было импортировано три модуля из библиотеки PyQt5: QtCore, QtGui, QtWidgets.
PyQt Designer - это визуальный редактор интерфейсов, которые работает вместе с PyQt5. Он позволяет создавать фреймы, надписи, кнопки, поля ввода и другие элементы пользовательского интерфейса, а затем использовать их на форме. После создания интерфейса в PyQt Designer, его можно сохранить в файл формата «.ui». Этот файл может быть загружен для использования в Python-приложений. Также, для создания графического интерфейса были импортированы такие классы, как: QtWidgets. QLabel и QtWidgets. QPushButton. Дизайн графического интерфейса изображен на рисунке 49.
QLabel и QPushButton - это классы виджетов из библиотеки PyQt5.
QLabel - используется для отображения текста и изображения в окне программы.
QPushButton - это кнопка для выполнения определенного действия. В нашей программе две кнопки данного класса - одна для выбора фото, а другая для запуска распознавания изображения.
Входными величинами будут изображения размером 416*416 пикселей, выходными данными будут названия классов информационных знаков.
Наш программный код создает главное окно размером 432*338 пикселей. Его пример представлен на рисунке 24.
 
Рисунок 24 - Дизайн графического интерфейса 
3.2.4 Проверка обученной нейронной сети на тестовом наборе 
После обучения и анализа его результатов мы можем попробовать нашу модель на тестовом наборе данных. В нем содержится 638 различных изображений, что составляет 13% от всех изображений.
На рисунке 25 мы можем наблюдать метрики оценки эффективности работы нашей модели на тестовом наборе данных.
 
Рисунок 25 - Метрики теста нейронной сети
Основываясь на наблюдаемых результатах, очевидно, что точность модели как в наборах валидационных, так и тестовых данных демонстрирует высокую степень сходства. Этот результат служит показателем того, что модель была соответствующим образом обучена.
На рисунках 26-31 выведены некоторые результаты детекции дорожных указателей нашей моделью.
 
Рисунок 26 - Обнаружение знака «Ограничение максимальной скорости 20 км/ч»
 
Рисунок 27 - Обнаружение указателя «Зеленый свет»
 
Рисунок 28 - Обнаружение знака «Ограничение максимальной скорости 80 км/ч»
 
Рисунок 29 - Обнаружение знака «Ограничение максимальной скорости 90 км/ч»
 
Рисунок 30 - Отсутствия распознавания указателя «Красный свет»
 
Рисунок 31 - Обнаружение указателя «Красный свет»




